# ðŸ§  Multiple Logistic Regression from Scratch (HR Attrition Analysis)

A **production-style Machine Learning project** implementing **Multiple Logistic Regression** using pure Python scripts (no notebooks), real-world HR data, and **matplotlib-based visualizations** to understand *why* employees leave a company.

This project focuses on **clarity, interpretability, and engineering discipline**, not just model accuracy.

---

## ðŸ“Œ Problem Statement

Employee attrition is a costly issue for organizations. The goal of this project is to:

> **Predict whether an employee will leave the company (1) or stay (0)**

using multiple features such as satisfaction level, evaluation score, working hours, department, salary, and promotion history.

This is a classic **binary classification problem** solved using **Multiple Logistic Regression**.

---

## ðŸ“‚ Dataset

* **Source**: Public HR Analytics dataset
* **Target Variable**: `left` (0 = Stayed, 1 = Left)
* **Size**: ~15,000 records
* **Type**: Real-world, imbalanced dataset

### Key Features

* `satisfaction_level`
* `last_evaluation`
* `number_project`
* `average_montly_hours`
* `time_spend_company`
* `Work_accident`
* `promotion_last_5years`
* `sales` (department â€“ categorical)
* `salary` (categorical)

---

## ðŸ—ï¸ Project Structure

```
logistic_regression_hr/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ HR_comma_sep.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ load_data.py        # Data loading
â”‚   â”œâ”€â”€ preprocess.py       # Encoding + Standardization
â”‚   â”œâ”€â”€ train.py            # Model training & evaluation
â”‚   â”œâ”€â”€ visualize.py        # Coefficient & confusion matrix plots
â”‚   â””â”€â”€ viz_sigmoid.py      # Logistic curve visualization
â”‚
â”œâ”€â”€ main.py                 # Pipeline execution
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

This structure mirrors **real ML codebases** and avoids notebook-driven workflows.

---

## ðŸ”§ Preprocessing Pipeline

âœ” One-Hot Encoding for categorical variables (`sales`, `salary`)
âœ” Feature standardization using `StandardScaler`
âœ” Labels left untouched (as required for classification)

Why this matters:

* Prevents string-to-float errors
* Ensures stable optimization
* Makes coefficients comparable

---

## ðŸ§® Model

* **Algorithm**: Multiple Logistic Regression
* **Library**: `scikit-learn`
* **Solver**: Default (lbfgs)
* **Regularization**: L2 (default)

Logistic regression was chosen for:

* Interpretability
* Probabilistic output
* Strong baseline performance

---

## ðŸ“ˆ Model Performance

* **Accuracy**: ~**0.78**

This is a realistic and expected result for this dataset.

âš ï¸ Note:
The dataset is **class-imbalanced** (~76% stay, ~24% leave). Therefore, accuracy alone is not sufficient and is interpreted alongside:

* Confusion Matrix
* Probability-based analysis

---

## ðŸ“Š Visualizations

All visualizations are done using **matplotlib only** (no seaborn, no notebooks).

### 1ï¸âƒ£ Feature Coefficient Plot

Shows how each feature impacts the probability of an employee leaving:

* Positive coefficient â†’ increases attrition probability
* Negative coefficient â†’ reduces attrition probability

### 2ï¸âƒ£ Confusion Matrix

Helps analyze:

* Correctly identified leavers
* Missed attrition cases
* Model usefulness beyond accuracy

### 3ï¸âƒ£ Logistic (Sigmoid) Curves â€” *Key Insight*

For each feature:

* The feature is varied across a standardized range
* All other features are held at their mean
* Resulting sigmoid curve is plotted

This allows visualization of:

* Direction of influence
* Strength of influence
* Decision boundary behavior

This is the **correct way** to visualize logistic regression in a multivariate setting.

---

## ðŸ§  Key Learnings

* Difference between **linear** and **logistic** regression
* Handling categorical variables correctly
* Importance of feature scaling
* Interpreting logistic coefficients
* Why accuracy can be misleading
* How probabilistic classifiers behave internally

---

## ðŸš€ How to Run

```bash
pip install -r requirements.txt
python main.py
```

All plots will render sequentially using matplotlib.

---

## ðŸ“Œ Why This Project Stands Out

âœ” Uses **real-world data**
âœ” No notebooks â€” clean Python scripts
âœ” Focus on **interpretability**, not just scores
âœ” Proper ML reasoning (scaling, imbalance, visualization)
âœ” Interview-ready explanations

---

## ðŸ”® Future Improvements

* ROC Curve & AUC visualization
* Precision, Recall, F1-score analysis
* Class-weighted logistic regression
* Threshold tuning
* Logistic regression from scratch (no sklearn)

---

## ðŸ‘¤ Author

**Maverick(Yashraj_Bhogade)**
Aspiring Machine Learning Engineer

---

> *This project was built to understand logistic regression deeply â€” not to chase artificial accuracy.*
